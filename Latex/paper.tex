\documentclass[11pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{authblk}

\geometry{a4paper, margin=1in}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{assumption}{Assumption}
\newtheorem{algorithm_thm}{Algorithm}

% Title
\title{\textbf{Tseng Splitting Method with Double Inertial Steps for Solving Monotone Inclusion Problems}}

% Authors
\author[1]{Zhong-bao Wang}
\author[1]{Zhen-yin Lei\thanks{Corresponding author. E-mail: leizheny@swpu.edu.cn}}
\author[1]{Xin Long}
\author[2]{Zhang-you Chen}

\affil[1]{School of Science, Southwest Petroleum University, Chengdu, Sichuan 610500, P.R. China}
\affil[2]{College of Mathematics and Information, China West Normal University, Nanchong, Sichuan 637009, P.R. China}

\date{}

\begin{document}

\maketitle

\begin{abstract}
In this paper, based on a double inertial extrapolation steps strategy and relaxation techniques, we introduce a new Tseng splitting method with double inertial extrapolation steps and self-adaptive step sizes for solving monotone inclusion problems in real Hilbert spaces. We prove weak and strong convergence theorems for the proposed algorithm under appropriate conditions. Finally, several numerical experiments are provided to illustrate the performance and theoretical outcomes of our algorithm.
\end{abstract}

\noindent\textbf{Keywords:} Tseng splitting method; monotone inclusion; double inertial steps; weak convergence; strong convergence

\noindent\textbf{2010 Mathematics Subject Classification:} 47H05, 47H09, 47J25, 65K15

\section{Introduction}

Let $H$ be a real Hilbert space with inner product $\langle \cdot, \cdot \rangle$ and induced norm $\|\cdot\|$. We consider the classical monotone inclusion problem, which is to
\begin{equation}\label{eq:mip}
\text{find } x^* \in H \text{ such that } 0 \in (A + B)x^*,
\end{equation}
where $A: H \to 2^H$ is a set-valued maximal monotone operator and $B: H \to H$ is a single-valued monotone and Lipschitz continuous operator. This problem plays an important role in many areas of applied mathematics, including signal processing, machine learning, and image recovery. Many optimization problems and variational inequalities can be modeled as special cases of problem \eqref{eq:mip}.

A classical method for solving problem \eqref{eq:mip} is the forward-backward splitting method, which was independently proposed by Passty \cite{passty1979} and Lions and Mercier \cite{lions1979}. Given $x_0 \in H$, the forward-backward splitting method generates a sequence $\{x_n\}$ by
\begin{equation}\label{eq:fbs}
x_{n+1} = J_{\lambda A}(x_n - \lambda B x_n), \quad \forall n \geq 0,
\end{equation}
where $\lambda > 0$ is a step size and $J_{\lambda A} = (I + \lambda A)^{-1}$ is the resolvent of $A$. Under appropriate conditions, the sequence $\{x_n\}$ generated by \eqref{eq:fbs} converges weakly to a solution of problem \eqref{eq:mip}.

To improve the convergence speed of the forward-backward splitting method, Tseng \cite{tseng2000} proposed a modified forward-backward splitting method (also known as forward-backward-forward splitting method), which generates a sequence $\{x_n\}$ by
\begin{equation}\label{eq:tseng}
\left\{
\begin{aligned}
y_n &= J_{\lambda A}(x_n - \lambda B x_n), \\
x_{n+1} &= y_n - \lambda(B y_n - B x_n), \quad \forall n \geq 0.
\end{aligned}
\right.
\end{equation}
The Tseng splitting method requires two evaluations of operator $B$ per iteration, but it allows for larger step sizes and has better convergence properties compared to the forward-backward splitting method.

In recent years, inertial methods have attracted much attention due to their ability to accelerate the convergence of iterative algorithms. The inertial technique was first introduced by Polyak \cite{polyak1964} in the context of gradient methods for unconstrained optimization. The basic idea of inertial methods is to use the information from the previous iterates to accelerate the convergence. The classical inertial forward-backward splitting method generates a sequence $\{x_n\}$ by
\begin{equation}\label{eq:ifbs}
\left\{
\begin{aligned}
w_n &= x_n + \alpha_n(x_n - x_{n-1}), \\
x_{n+1} &= J_{\lambda A}(w_n - \lambda B w_n), \quad \forall n \geq 1,
\end{aligned}
\right.
\end{equation}
where $\alpha_n \in [0, 1)$ is an inertial parameter. The inertial forward-backward splitting method has been extensively studied and generalized by many researchers; see, e.g., \cite{alvarez2001,attouch2016,bot2015,lorenz2015} and the references therein.

Recently, double inertial extrapolation steps have been introduced to further accelerate the convergence of iterative algorithms. The double inertial technique uses two inertial terms instead of one, which can provide better acceleration in certain situations. Motivated by the double inertial technique and relaxation methods, in this paper, we propose a new Tseng splitting method with double inertial extrapolation steps for solving the monotone inclusion problem \eqref{eq:mip}.

The rest of this paper is organized as follows. In Section 2, we recall some definitions and lemmas that will be used in the subsequent analysis. In Section 3, we introduce our new algorithm and prove its weak convergence under appropriate conditions. In Section 4, we prove strong convergence of a modified version of our algorithm. In Section 5, we present some numerical experiments to illustrate the performance of our algorithm. Finally, we give some concluding remarks in Section 6.

\section{Preliminaries}

In this section, we recall some definitions and lemmas that will be used in the subsequent analysis. Throughout this paper, we denote by $H$ a real Hilbert space with inner product $\langle \cdot, \cdot \rangle$ and induced norm $\|\cdot\|$. We use $\rightharpoonup$ and $\to$ to denote weak convergence and strong convergence, respectively. For a set $C \subset H$, we denote by $\text{int}(C)$ the interior of $C$.

\begin{definition}
Let $A: H \to 2^H$ be a set-valued operator. The domain and graph of $A$ are defined as
\begin{align*}
D(A) &= \{x \in H : Ax \neq \emptyset\}, \\
G(A) &= \{(x, u) \in H \times H : x \in D(A), u \in Ax\}.
\end{align*}
The inverse of $A$ is defined as $A^{-1}v = \{x \in H : v \in Ax\}$ for all $v \in H$.
\end{definition}

\begin{definition}
A set-valued operator $A: H \to 2^H$ is said to be monotone if
\[
\langle u - v, x - y \rangle \geq 0, \quad \forall (x, u), (y, v) \in G(A).
\]
A monotone operator $A$ is said to be maximal monotone if there exists no monotone operator $B: H \to 2^H$ such that $G(B)$ properly contains $G(A)$.
\end{definition}

\begin{definition}
Let $B: H \to H$ be a single-valued operator. $B$ is said to be:
\begin{enumerate}
    \item[(i)] monotone if $\langle Bx - By, x - y \rangle \geq 0$ for all $x, y \in H$;
    \item[(ii)] $L$-Lipschitz continuous if there exists $L > 0$ such that $\|Bx - By\| \leq L\|x - y\|$ for all $x, y \in H$;
    \item[(iii)] $\beta$-cocoercive if there exists $\beta > 0$ such that $\langle Bx - By, x - y \rangle \geq \beta\|Bx - By\|^2$ for all $x, y \in H$.
\end{enumerate}
\end{definition}

\begin{definition}
Let $A: H \to 2^H$ be a maximal monotone operator and $\lambda > 0$. The resolvent of $A$ is defined as
\[
J_{\lambda A} = (I + \lambda A)^{-1},
\]
where $I$ is the identity operator on $H$.
\end{definition}

\begin{lemma}\label{lem:resolvent}
Let $A: H \to 2^H$ be a maximal monotone operator and $\lambda > 0$. Then:
\begin{enumerate}
    \item[(i)] $J_{\lambda A}$ is single-valued and defined on all of $H$;
    \item[(ii)] $J_{\lambda A}$ is firmly nonexpansive, i.e., $\|J_{\lambda A}x - J_{\lambda A}y\|^2 \leq \langle J_{\lambda A}x - J_{\lambda A}y, x - y \rangle$ for all $x, y \in H$;
    \item[(iii)] $\text{Fix}(J_{\lambda A}) = A^{-1}(0)$, where $\text{Fix}(J_{\lambda A})$ denotes the set of fixed points of $J_{\lambda A}$.
\end{enumerate}
\end{lemma}

\begin{lemma}\label{lem:sum}
Let $A: H \to 2^H$ be a maximal monotone operator and $B: H \to H$ be a monotone and Lipschitz continuous operator. Then $A + B$ is maximal monotone.
\end{lemma}

\begin{lemma}\label{lem:opial}
(Opial's Lemma) Let $H$ be a real Hilbert space and let $\{x_n\}$ be a sequence in $H$. Suppose that there exists a nonempty subset $S$ of $H$ such that:
\begin{enumerate}
    \item[(i)] For every $z \in S$, $\lim_{n \to \infty}\|x_n - z\|$ exists;
    \item[(ii)] Every weak sequential cluster point of $\{x_n\}$ belongs to $S$.
\end{enumerate}
Then $\{x_n\}$ converges weakly to a point in $S$.
\end{lemma}

\begin{lemma}\label{lem:identity}
Let $H$ be a real Hilbert space. Then for all $x, y \in H$ and $\alpha \in \mathbb{R}$, we have
\[
\|\alpha x + (1 - \alpha)y\|^2 = \alpha\|x\|^2 + (1 - \alpha)\|y\|^2 - \alpha(1 - \alpha)\|x - y\|^2.
\]
\end{lemma}

\begin{lemma}\label{lem:xu}
Let $\{a_n\}$ be a sequence of nonnegative real numbers satisfying
\[
a_{n+1} \leq (1 - \gamma_n)a_n + \gamma_n \delta_n + \sigma_n, \quad \forall n \geq 1,
\]
where $\{\gamma_n\}$, $\{\delta_n\}$, and $\{\sigma_n\}$ are sequences of real numbers such that:
\begin{enumerate}
    \item[(i)] $\{\gamma_n\} \subset (0, 1)$ and $\sum_{n=1}^{\infty}\gamma_n = \infty$;
    \item[(ii)] $\limsup_{n \to \infty}\delta_n \leq 0$ or $\sum_{n=1}^{\infty}\gamma_n|\delta_n| < \infty$;
    \item[(iii)] $\sigma_n \geq 0$ for all $n \geq 1$ and $\sum_{n=1}^{\infty}\sigma_n < \infty$.
\end{enumerate}
Then $\lim_{n \to \infty}a_n = 0$.
\end{lemma}

% References (placeholder - would typically use BibTeX)
\begin{thebibliography}{99}

\bibitem{alvarez2001}
F. Alvarez, Weak convergence of a relaxed and inertial hybrid projection-proximal point algorithm for maximal monotone operators in Hilbert space, SIAM J. Optim. 14 (2004) 773--782.

\bibitem{attouch2016}
H. Attouch, J. Peypouquet, P. Redont, Fast convex optimization via inertial dynamics with Hessian driven damping, J. Differential Equations 261 (2016) 5734--5783.

\bibitem{bot2015}
R.I. Bo\c{t}, E.R. Csetnek, An inertial forward-backward-forward primal-dual splitting algorithm for solving monotone inclusion problems, Numer. Algorithms 71 (2016) 519--540.

\bibitem{lions1979}
P.L. Lions, B. Mercier, Splitting algorithms for the sum of two nonlinear operators, SIAM J. Numer. Anal. 16 (1979) 964--979.

\bibitem{lorenz2015}
D.A. Lorenz, T. Pock, An inertial forward-backward algorithm for monotone inclusions, J. Math. Imaging Vision 51 (2015) 311--325.

\bibitem{passty1979}
G.B. Passty, Ergodic convergence to a zero of the sum of monotone operators in Hilbert space, J. Math. Anal. Appl. 72 (1979) 383--390.

\bibitem{polyak1964}
B.T. Polyak, Some methods of speeding up the convergence of iteration methods, USSR Comput. Math. Math. Phys. 4 (1964) 1--17.

\bibitem{tseng2000}
P. Tseng, A modified forward-backward splitting method for maximal monotone mappings, SIAM J. Control Optim. 38 (2000) 431--446.

\end{thebibliography}

\end{document}
